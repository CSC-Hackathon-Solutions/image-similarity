{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ba8bcaa6-3626-44f2-8418-820e8545908d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T20:00:28.027180Z",
     "start_time": "2023-07-01T20:00:28.023417Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from DataHandlers import ImageDataset, InMemDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2fcde548-9172-47d9-a57f-f7c9e217bfa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Wrapper():\n",
    "    def __init__(\n",
    "                self, \n",
    "                model, \n",
    "                paths = {'train': 'data/train.csv', 'submit': 'data/submit.csv'},\n",
    "                transform = None,\n",
    "                batch_size = 20,\n",
    "            ):\n",
    "        \n",
    "        self.model = model\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        if transform is None:\n",
    "            transform = T.Compose([\n",
    "                T.Resize(200),\n",
    "                T.CenterCrop(200),\n",
    "                T.ToTensor(),\n",
    "                #T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])\n",
    "\n",
    "        train = pd.read_csv(paths['train'])  \n",
    "        n = len(train)\n",
    "        \n",
    "        submit = pd.read_csv(paths['submit'])\n",
    "        self.max_submit_id = len(submit)\n",
    "        \n",
    "        dataset_types = ['train', 'valid', 'test', 'submit']        \n",
    "        self.datasets = {\n",
    "            'train'  : ImageDataset(train[:int(n * 0.8)], transform=transform),\n",
    "            'valid'  : ImageDataset(train[int(n * 0.8):int(n * 0.9)], transform=transform),\n",
    "            'test'   : ImageDataset(train[int(n * 0.9):], transform=transform),\n",
    "            'submit' : ImageDataset(submit, transform=transform)\n",
    "        }\n",
    "        \n",
    "        self.loaders = {\n",
    "            dataset_type: DataLoader(dataset, self.batch_size, shuffle=(dataset_type=='train'))\n",
    "            for dataset_type, dataset in self.datasets.items()\n",
    "        } \n",
    "        \n",
    "    def train(self,):\n",
    "        print('Started training model')\n",
    "        self.model.train(self.loaders['train'])\n",
    "        print('Finished training model\\n')\n",
    "        \n",
    "    def fscore(self, sample_size=100):\n",
    "        def _count(loader):\n",
    "            preds, truth = [], []\n",
    "            items_count = 0\n",
    "            for images1, images2, equal in loader:\n",
    "                preds.append(self.model.predict(images1, images2))\n",
    "                truth.append(equal)\n",
    "                items_count += self.batch_size\n",
    "                if items_count > sample_size: break\n",
    "\n",
    "            preds = torch.cat(preds)\n",
    "            truth = torch.cat(truth)\n",
    "\n",
    "            # convert the predictions to binary labels\n",
    "            preds_bin = (preds > 0.5).int()\n",
    "\n",
    "            # compute F1 score\n",
    "            f1 = f1_score(truth.numpy(), preds_bin.numpy())\n",
    "\n",
    "            return f1\n",
    "    \n",
    "        print('Started calculating f-scores')\n",
    "        print(f'Train      : {_count(self.loaders[\"train\"]): .3f}%') \n",
    "        print(f'Validation : {_count(self.loaders[\"valid\"]): .3f}%') \n",
    "        print(f'Test       : {_count(self.loaders[\"test\"]): .3f}%\\n') \n",
    "    \n",
    "    def _test_loaders(self):\n",
    "        to_show = {}\n",
    "        for loader_type, loader in self.loaders.items():\n",
    "            image1, image2, _ = next(iter(loader))\n",
    "            image1 = image1[0]\n",
    "            image2 = image2[0]\n",
    "            to_show[loader_type + '-1'] = image1\n",
    "            to_show[loader_type + '-2'] = image2\n",
    "        num_images = len(to_show)\n",
    "        fig, axs = plt.subplots(1, num_images, figsize=(15, 15))\n",
    "\n",
    "        for i, (name, img) in enumerate(to_show.items()):\n",
    "            axs[i].imshow(img.numpy().transpose(1,2,0).clip(0, 254), cmap='gray')\n",
    "            axs[i].set_title(name)\n",
    "            axs[i].axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def mislabeled(self, loader='test'):\n",
    "        loader = self.loaders[loader]\n",
    "\n",
    "        def mislabeled_inner():\n",
    "            for images1, images2, equal in loader:\n",
    "                preds = self.model.predict(images1, images2)\n",
    "                if (preds == equal).all(): \n",
    "                    continue\n",
    "                else:\n",
    "                    for index in (preds != equal).nonzero():\n",
    "                        yield (images1[index], images2[index], preds[index], equal[index])\n",
    "\n",
    "        button = widgets.Button(description=\"Next Images\")\n",
    "        output = widgets.Output()\n",
    "\n",
    "        def on_button_clicked(b):\n",
    "            with output:\n",
    "                clear_output()\n",
    "                image1, image2, pred, truth = next(mislabeled_gen)\n",
    "                print(((image1-image2)**2).mean())\n",
    "                fig, axs = plt.subplots(1, 2, figsize=(10,6))\n",
    "                axs[0].imshow(image1.squeeze().numpy().transpose(1,2,0))\n",
    "                axs[1].imshow(image2.squeeze().numpy().transpose(1,2,0))\n",
    "                fig.suptitle(f'Predicted: {pred.item()}\\nTruth: {truth.item()}')\n",
    "                plt.show()\n",
    "\n",
    "        button.on_click(on_button_clicked)\n",
    "        display(button, output)\n",
    "        mislabeled_gen = mislabeled_inner()\n",
    "        on_button_clicked(None)  # show the first images\n",
    "\n",
    "            \n",
    "        \n",
    "    def save_test_preds(self, path='res.csv'):\n",
    "        print(f'Started saving test predictions to {path}')\n",
    "        ids = []\n",
    "        preds = []\n",
    "            \n",
    "        for images1, images2, id_ in tqdm(self.loaders['submit']):\n",
    "            preds.extend(self.model.predict(images1, images2))\n",
    "            ids.extend(id_)\n",
    "            \n",
    "        all_ids = pd.DataFrame({\n",
    "            'ID': range(2, self.max_submit_id),\n",
    "        })\n",
    "        res = pd.DataFrame({\n",
    "            'ID': [obj.item() for obj in ids],\n",
    "            'is_same': [obj.item() for obj in preds]\n",
    "        }).drop_duplicates()\n",
    "\n",
    "        res = all_ids.merge(res, on='ID', how='left').fillna(0)\n",
    "        res.to_csv(path, index=False)\n",
    "        print(f'Saved test predictions to {path}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2a5e92be-422c-437a-b986-afd804ad3230",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ThresholdClassifier():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, loader):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, images1, images2):\n",
    "        delta = ((images1 - images2) ** 2).mean(dim=(1,2,3))\n",
    "        preds = (delta < 0.025) * 1\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4c4f487c-30f4-48eb-ad6d-fe3b26a61174",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training model\n",
      "Finished training model\n",
      "\n",
      "Started calculating f-scores\n",
      "Train      :  0.973%\n",
      "Validation :  0.990%\n",
      "Test       :  0.994%\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5548334089314f3ba054970d916c433b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Next Images', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6bcfe1baff451fb29eb8e8bfdd0c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ThresholdClassifier()\n",
    "wrapper = Wrapper(model)\n",
    "wrapper.train()\n",
    "wrapper.fscore(sample_size=500)\n",
    "wrapper.mislabeled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986efa61-8b78-426f-9b3f-f65591223931",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
