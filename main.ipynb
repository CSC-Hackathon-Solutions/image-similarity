{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba8bcaa6-3626-44f2-8418-820e8545908d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T20:00:28.027180Z",
     "start_time": "2023-07-01T20:00:28.023417Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.9/site-packages/torchvision/image.so, 0x0006): symbol not found in flat namespace '__ZN3c106detail19maybe_wrap_dim_slowIxEET_S2_S2_b''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from DataHandlers import ImageDataset, InMemDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fcde548-9172-47d9-a57f-f7c9e217bfa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ThresholdModel():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, loader):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, loader):\n",
    "        for batch in loader:\n",
    "            images1, images2, ids = batch\n",
    "            delta = ((images1 - images2) ** 2).mean(dim=(1,2,3))\n",
    "            pred = (delta < 0.02) * 1\n",
    "            yield pred\n",
    "\n",
    "class Wrapper():\n",
    "    def __init__(\n",
    "                self, \n",
    "                model, \n",
    "                paths = {'train': 'data/train.csv', 'valid': 'data/valid.csv', 'test': 'data/test.csv'},\n",
    "                sample_sizes = {'train': 100, 'valid': 100, 'test': 100},\n",
    "                transform = None,\n",
    "                inMemLoaders = False\n",
    "            ):\n",
    "        \n",
    "        self.model = model\n",
    "        self.paths = paths\n",
    "        self.sample_sizes = sample_sizes\n",
    "        \n",
    "        def _create_metadata(dataset_type):\n",
    "            if dataset_type == 'train':\n",
    "                return pd.read_csv(paths['train'])[:sample_sizes['train']]\n",
    "            elif dataset_type == 'valid':\n",
    "                return pd.read_csv(paths['valid'])[:sample_sizes['valid']]\n",
    "            elif dataset_type == 'test':\n",
    "                return pd.read_csv(paths['test'])[:sample_sizes['test']]\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown dataset type: {dataset_type}\")\n",
    "\n",
    "        def _create_dataloader(dataset, batch_size, shuffle):\n",
    "            if inMemLoaders:\n",
    "                return InMemDataLoader(\n",
    "                    dataset,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=shuffle,\n",
    "                )\n",
    "            else:\n",
    "                return DataLoader(\n",
    "                    dataset,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=shuffle,\n",
    "                )\n",
    "        \n",
    "        if transform is None:\n",
    "            transform = T.Compose([\n",
    "                T.Resize(200),\n",
    "                T.CenterCrop(200),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])\n",
    "\n",
    "        dataset_types = ['train', 'valid', 'test']\n",
    "\n",
    "        self.datasets = {\n",
    "            dataset_type: ImageDataset(_create_metadata(dataset_type), transform=transform)\n",
    "            for dataset_type in dataset_types\n",
    "        }\n",
    "\n",
    "        self.loaders = {\n",
    "            dataset_type: _create_dataloader(dataset, batch_size=20, shuffle=(dataset_type=='train'))\n",
    "            for dataset_type, dataset in self.datasets.items()\n",
    "        }\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        self.model.train(self.loaders['train'])\n",
    "        \n",
    "    def accuracy(self):\n",
    "        train_preds = self.model.predict(self.loaders['valid'])\n",
    "        \n",
    "        n, true_preds = 0, 0\n",
    "        for (_, _, truth), pred in zip(self.loaders['valid'], train_preds):\n",
    "            true_preds += len((truth == pred).nonzero())\n",
    "            n += len(pred)\n",
    "            \n",
    "        print(f'Validation accuracy: {true_preds / n}')\n",
    "        \n",
    "    def save_test_preds(self, path='res.csv'):\n",
    "        ids = []\n",
    "        preds = []\n",
    "\n",
    "        for batch in self.loaders['test']:\n",
    "            ids.extend(batch[2])\n",
    "            \n",
    "        for p in self.model.predict(self.loaders['test']):\n",
    "            preds.extend(p)\n",
    "        \n",
    "        all_ids = pd.DataFrame({\n",
    "            'ID': range(2, len(self.loaders['test'])),\n",
    "        })\n",
    "        res = pd.DataFrame({\n",
    "            'ID': [obj.item() for obj in ids],\n",
    "            'is_same': [obj.item() for obj in preds]\n",
    "        }).drop_duplicates()\n",
    "\n",
    "        res = all_ids.merge(res, on='ID', how='left').fillna(0)\n",
    "        res.to_csv(path, index=False)\n",
    "        print(f'Saved test predictions to {path}')\n",
    "        \n",
    "model = ThresholdModel()\n",
    "wrapper = Wrapper(model)\n",
    "wrapper.train()\n",
    "wrapper.accuracy()\n",
    "wrapper.save_test_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4f487c-30f4-48eb-ad6d-fe3b26a61174",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
