{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba8bcaa6-3626-44f2-8418-820e8545908d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.9/site-packages/torchvision/image.so, 0x0006): symbol not found in flat namespace '__ZN3c106detail19maybe_wrap_dim_slowIxEET_S2_S2_b''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from ImageDataset import ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0742ffbf-b1ac-4409-a174-92b52ebb8a8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('data/train.csv')\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.CenterCrop((200, 200)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = ImageDataset(metadata, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26b4398c-3f1d-4410-8957-13df738e989b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InMemDataLoader(object):\n",
    "    \"\"\"\n",
    "    A data loader that keeps all data in CPU or GPU memory.\n",
    "    \"\"\"\n",
    "\n",
    "    __initialized = False\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        sampler=None,\n",
    "        batch_sampler=None,\n",
    "        drop_last=False,\n",
    "        augment=False,\n",
    "    ):\n",
    "        \"\"\"A torch dataloader that fetches data from memory.\"\"\"\n",
    "        batches = []\n",
    "        for i in tqdm(range(len(dataset))):\n",
    "            batch = [t.clone().detach() for t in dataset[i]]\n",
    "            batches.append(batch)\n",
    "        tensors = [torch.stack(ts) for ts in zip(*batches)]\n",
    "        dataset = torch.utils.data.TensorDataset(*tensors)\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.drop_last = drop_last\n",
    "        self.augment = augment\n",
    "\n",
    "        if batch_sampler is not None:\n",
    "            if batch_size > 1 or shuffle or sampler is not None or drop_last:\n",
    "                raise ValueError(\n",
    "                    \"batch_sampler option is mutually exclusive \"\n",
    "                    \"with batch_size, shuffle, sampler, and \"\n",
    "                    \"drop_last\"\n",
    "                )\n",
    "            self.batch_size = None\n",
    "            self.drop_last = None\n",
    "\n",
    "        if sampler is not None and shuffle:\n",
    "            raise ValueError(\"sampler option is mutually exclusive with \" \"shuffle\")\n",
    "\n",
    "        if batch_sampler is None:\n",
    "            if sampler is None:\n",
    "                if shuffle:\n",
    "                    sampler = torch.utils.data.RandomSampler(dataset)\n",
    "                else:\n",
    "                    sampler = torch.utils.data.SequentialSampler(dataset)\n",
    "            batch_sampler = torch.utils.data.BatchSampler(\n",
    "                sampler, batch_size, drop_last\n",
    "            )\n",
    "\n",
    "        self.sampler = sampler\n",
    "        self.batch_sampler = batch_sampler\n",
    "        self.__initialized = True\n",
    "\n",
    "    def __setattr__(self, attr, val):\n",
    "        if self.__initialized and attr in (\"batch_size\", \"sampler\", \"drop_last\"):\n",
    "            raise ValueError(\n",
    "                \"{} attribute should not be set after {} is \"\n",
    "                \"initialized\".format(attr, self.__class__.__name__)\n",
    "            )\n",
    "\n",
    "        super(InMemDataLoader, self).__setattr__(attr, val)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch_indices in self.batch_sampler:\n",
    "            batch = self.dataset[batch_indices]\n",
    "            if self.augment:\n",
    "                xs = []\n",
    "                ys = []\n",
    "                ts = T.Compose([\n",
    "                    T.ToPILImage(),\n",
    "                    T.RandomRotation(10),\n",
    "                    T.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 1)),\n",
    "                    T.ToTensor(),\n",
    "                ])\n",
    "                num_samples = 2\n",
    "                for x, y in zip(batch[0], batch[1]):\n",
    "                    for _ in range(num_samples):\n",
    "                        xs.append(ts(x))\n",
    "                        ys.append(y)\n",
    "                yield(torch.stack(xs), torch.stack(ys))\n",
    "            else:\n",
    "                yield batch\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batch_sampler)\n",
    "\n",
    "    def to(self, device):\n",
    "        self.dataset.tensors = tuple(t.to(device) for t in self.dataset.tensors)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a73e5df-d500-4cb7-923d-cd26a833e92d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686eb90edcaa43bbac81ff8225200a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loader = InMemDataLoader(\n",
    "    dataset,\n",
    "    batch_size=10,\n",
    "    shuffle=True,\n",
    "    sampler=None,\n",
    "    batch_sampler=None,\n",
    "    drop_last=False,\n",
    "    augment=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dd3c74-ce53-4c36-af33-5c2e77098b05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
