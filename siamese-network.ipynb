{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Basic imports\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchmetrics.classification import BinaryF1Score\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from DataHandlers import ImageDataset, InMemDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df, ratio, shuffle=True):\n",
    "    assert(sum(ratio) == 1)\n",
    "    if shuffle:\n",
    "        df = df.sample(frac=1)\n",
    "    return np.split(df, (np.cumsum(ratio[:-1]) * df.shape[0]).astype(int))\n",
    "\n",
    "def denormalize_tensor(img):\n",
    "    return (img.permute(1, 2, 0) + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "max_submit_id = 22661"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.Resize(200),\n",
    "    T.CenterCrop(200),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "df_slices = list(split_dataframe(pd.read_csv('data/train.csv'), (0.9, 0.01, 0.04, 0.05)))\n",
    "\n",
    "datasets = [ImageDataset(df, transform=transform) for df in df_slices]\n",
    "loaders = [DataLoader(dataset, batch_size=batch_size, shuffle=True) for dataset in datasets]\n",
    "\n",
    "train_dataset, train_threshold_dataset, valid_dataset, test_dataset = datasets\n",
    "train_loader, train_threshold_loader, valid_loader, test_loader = loaders\n",
    "\n",
    "submit_df = pd.read_csv('data/submit.csv')\n",
    "submit_dataset = ImageDataset(submit_df, transform=transform)\n",
    "submit_loader = DataLoader(submit_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loader_images(loader):\n",
    "    print('Examples of images from loader:')\n",
    "    image1, image2, _ = next(iter(loader))\n",
    "    image1 = image1[0]\n",
    "    image2 = image2[0]\n",
    "    _, axs = plt.subplots(1, 2, figsize=(15, 15))\n",
    "\n",
    "    axs[0].imshow(denormalize_tensor(image1))\n",
    "    axs[0].set_title('Image 1')\n",
    "    axs[0].axis('off')\n",
    "    axs[1].imshow(denormalize_tensor(image2))\n",
    "    axs[1].set_title('Image 2')\n",
    "    axs[1].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "        \n",
    "\"\"\"\n",
    "    Tries to find and show mislabeled images from the specified loader.\n",
    "\"\"\"\n",
    "def mislabeled(model, loader):\n",
    "    def mislabeled_inner():\n",
    "        for images1, images2, equal in loader:\n",
    "            preds = model.predict(images1, images2)\n",
    "            for index in (preds != equal).nonzero().reshape(-1).tolist():\n",
    "                yield (images1[index], images2[index], preds[index], equal[index])\n",
    "\n",
    "    button = widgets.Button(description=\"Next Images\")\n",
    "    output = widgets.Output()\n",
    "\n",
    "    def on_button_clicked(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            image1, image2, pred, truth = next(mislabeled_gen)\n",
    "            fig, axs = plt.subplots(1, 3, figsize=(14,7))\n",
    "            axs[0].imshow(denormalize_tensor(image1))\n",
    "            axs[1].imshow(denormalize_tensor(image2))\n",
    "            axs[2].imshow(np.abs(denormalize_tensor(image1 - image2)))\n",
    "            suptitle = f'Predicted: {pred.item()}\\nTruth: {truth.item()}'\n",
    "            # try:\n",
    "            #     suptitle += f'\\nmodel.forward(): {model.forward(image1, image2)}'\n",
    "            # except:\n",
    "            #     pass\n",
    "            fig.suptitle(suptitle)\n",
    "            plt.show()\n",
    "\n",
    "    button.on_click(on_button_clicked)\n",
    "    display(button, output)\n",
    "    mislabeled_gen = mislabeled_inner()\n",
    "    on_button_clicked(None)  # show the first images\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Saves predictions that should be submitted to kaggle.\n",
    "\"\"\"\n",
    "def save_test_preds(model, loader, max_submit_id, path='res.csv'):\n",
    "    print(f'Started saving test predictions to {path}')\n",
    "    ids = []\n",
    "    preds = []\n",
    "        \n",
    "    for images1, images2, id_ in tqdm(loader):\n",
    "        preds.extend(model.predict(images1, images2))\n",
    "        ids.extend(id_)\n",
    "        \n",
    "    all_ids = pd.DataFrame({\n",
    "        'ID': range(2, max_submit_id + 1),\n",
    "    })\n",
    "    res = pd.DataFrame({\n",
    "        'ID': [obj.item() for obj in ids],\n",
    "        'is_same': [obj.item() for obj in preds]\n",
    "    }).drop_duplicates()\n",
    "\n",
    "    res = all_ids.merge(res, on='ID', how='left').fillna(0)\n",
    "    res.to_csv(path, index=False)\n",
    "    print(f'Saved test predictions to {path}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, distance, label):\n",
    "        loss_contrastive = torch.mean(label * torch.pow(distance, 2) +\n",
    "                                      (1 - label) * torch.pow(torch.clamp(self.margin - distance, min=0), 2))\n",
    "\n",
    "        return loss_contrastive\n",
    "\n",
    "class SiameseNetworkClassifier(nn.Module):\n",
    "    def __init__(self, device='mps'):\n",
    "        super(SiameseNetworkClassifier, self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(67712, 50)\n",
    "        )\n",
    "        self.threshold = torch.tensor(0.)\n",
    "        \n",
    "        self.device = torch.device(device)\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, images1, images2):\n",
    "        output1 = self.layers(images1)\n",
    "        output2 = self.layers(images2)\n",
    "        return F.pairwise_distance(output1, output2)\n",
    "        \n",
    "    def update_threshold(self, loader, max_batches=None):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            distances = []\n",
    "            labels = []\n",
    "            for images1, images2, equals in islice(tqdm(loader, desc='Calculating threshold'), max_batches):\n",
    "                distance = self.forward(images1.to(self.device), images2.to(self.device))\n",
    "                distances.append(distance.cpu())\n",
    "                labels.append(equals)\n",
    "    \n",
    "            distances = torch.cat(distances)\n",
    "            labels = torch.cat(labels)\n",
    "            log_reg = LogisticRegression(penalty=None)\n",
    "            log_reg.fit(distances.reshape((-1, 1)), labels)\n",
    "            self.threshold = (-log_reg.intercept_ / log_reg.coef_).item()\n",
    "\n",
    "    # TODO refactor this method so we don't have to call .to(self.device) ? \n",
    "    def predict(self, images1, images2):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            images1 = images1.to(self.device)\n",
    "            images2 = images2.to(self.device)\n",
    "            distances = self.forward(images1, images2)\n",
    "            return (distances < self.threshold).int().cpu()\n",
    "\n",
    "def evaluate(model, loader, max_batches=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pos_f1 = BinaryF1Score()\n",
    "        neg_f1 = BinaryF1Score()\n",
    "        for images1, images2, label in islice(tqdm(loader, desc='Evaluating model'), max_batches):\n",
    "            distance = model.forward(images1.to(model.device), images2.to(model.device)).cpu()\n",
    "            pos_f1.update(distance < model.threshold, label)\n",
    "            neg_f1.update(distance > model.threshold, 1 - label)\n",
    "    return (pos_f1.compute() + neg_f1.compute()) / 2\n",
    "    \n",
    "def train(model, train_loader, train_threshold_loader, valid_loader, test_loader, epochs=20, lr=1e-4, max_batches=None):\n",
    "    print(\"Debug: Initializing ContrastiveLoss and Optimizer\")\n",
    "    criterion = ContrastiveLoss().to(model.device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for images1, images2, label in islice(tqdm(train_loader, desc='Training model'), max_batches):\n",
    "            model.train()\n",
    "            images1 = images1.to(model.device)\n",
    "            images2 = images2.to(model.device)\n",
    "            label = label.to(model.device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model.forward(images1, images2)\n",
    "            loss = criterion(outputs, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.update_threshold(train_threshold_loader, max_batches=max_batches)\n",
    "        \n",
    "        print(f'Epoch {epoch} | Loss:{loss.item()}')\n",
    "        print(f'Train accuracy: {evaluate(model, train_loader, max_batches=max_batches)}')\n",
    "        print(f'Valid accuracy: {evaluate(model, valid_loader, max_batches=max_batches)}')\n",
    "    print(f'Test accuracy: {evaluate(model, test_loader, max_batches=max_batches)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = SiameseNetworkClassifier()\n",
    "train(model, *loaders, epochs=1, max_batches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Check on what's wrong with our model\n",
    "\"\"\"\n",
    "\n",
    "mislabeled(model, valid_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
