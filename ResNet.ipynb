{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Imports\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import os\n",
    "from itertools import islice\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchmetrics.classification import BinaryF1Score\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    https://towardsdatascience.com/contrastive-loss-explaned-159f2d4a87ec for more details \n",
    "\"\"\"\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, distance, label):\n",
    "        loss_contrastive = torch.mean(label * torch.pow(distance, 2) +\n",
    "                                      (1 - label) * torch.pow(torch.clamp(self.margin - distance, min=0), 2))\n",
    "\n",
    "        return loss_contrastive\n",
    "\n",
    "\"\"\"\n",
    "    https://towardsdatascience.com/a-friendly-introduction-to-siamese-networks-85ab17522942\n",
    "\"\"\"\n",
    "\n",
    "class SiameseNetworkClassifier(nn.Module):\n",
    "    def __init__(self, device='mps'):\n",
    "        super(SiameseNetworkClassifier, self).__init__()\n",
    "\n",
    "        # Replace with frozen ResNet152 feature layers\n",
    "        resnet = models.resnet152(pretrained=True)\n",
    "        # Freeze all layers\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Split the model into frozen and hot layers\n",
    "        self.frozen = nn.Sequential(*list(resnet.children())[:-1]) \n",
    "        self.hot = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(resnet.fc.in_features, 50)\n",
    "        )\n",
    "\n",
    "        self.threshold = torch.tensor(0.)\n",
    "\n",
    "        self.device = torch.device(device)\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, images1, images2):\n",
    "        output1 = self.hot(self.frozen(images1))\n",
    "        output2 = self.hot(self.frozen(images2))\n",
    "        return F.pairwise_distance(output1, output2)\n",
    "        \n",
    "    def update_threshold(self, loader, max_batches=None):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            distances = []\n",
    "            labels = []\n",
    "            for images1, images2, equals in islice(tqdm(loader, desc='Calculating threshold'), max_batches):\n",
    "                distance = self.forward(images1.to(self.device), images2.to(self.device))\n",
    "                distances.append(distance.cpu())\n",
    "                labels.append(equals)\n",
    "    \n",
    "            distances = torch.cat(distances)\n",
    "            labels = torch.cat(labels)\n",
    "            log_reg = LogisticRegression(penalty=None)\n",
    "            log_reg.fit(distances.reshape((-1, 1)), labels)\n",
    "            self.threshold = (-log_reg.intercept_ / log_reg.coef_).item()\n",
    "\n",
    "    # TODO refactor this method so we don't have to call .to(self.device) ? \n",
    "    def predict(self, images1, images2):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            images1 = images1.to(self.device)\n",
    "            images2 = images2.to(self.device)\n",
    "            distances = self.forward(images1, images2)\n",
    "            return (distances < self.threshold).int().cpu()\n",
    "\n",
    "def evaluate(model, loader, max_batches=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pos_f1 = BinaryF1Score()\n",
    "        neg_f1 = BinaryF1Score()\n",
    "        for images1, images2, label in islice(tqdm(loader, desc='Evaluating model'), max_batches):\n",
    "            distance = model.forward(images1.to(model.device), images2.to(model.device)).cpu()\n",
    "            pos_f1.update(distance < model.threshold, label)\n",
    "            neg_f1.update(distance > model.threshold, 1 - label)\n",
    "    return (pos_f1.compute() + neg_f1.compute()) / 2\n",
    "    \n",
    "def train(model, train_loader, train_threshold_loader, valid_loader, test_loader, epochs=20, lr=1e-4, max_batches=None):\n",
    "    print(\"Debug: Initializing ContrastiveLoss and Optimizer\")\n",
    "    criterion = ContrastiveLoss().to(model.device)\n",
    "    optimizer = torch.optim.Adam(model.hot.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for images1, images2, label in islice(tqdm(train_loader, desc='Training model'), max_batches):\n",
    "            model.train()\n",
    "            images1 = images1.to(model.device)\n",
    "            images2 = images2.to(model.device)\n",
    "            label = label.to(model.device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model.forward(images1, images2)\n",
    "            loss = criterion(outputs, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.update_threshold(train_threshold_loader, max_batches=max_batches)\n",
    "        \n",
    "        print(f'Epoch {epoch} | Loss:{loss.item()}')\n",
    "        print(f'Train fscore: {evaluate(model, train_loader, max_batches=max_batches)}')\n",
    "        print(f'Valid fscore: {evaluate(model, valid_loader, max_batches=max_batches)}')\n",
    "    print(f'Test fscore: {evaluate(model, test_loader, max_batches=max_batches)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "max_submit_id = 22661"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.Resize(400),\n",
    "    T.CenterCrop(350),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "df_slices = list(split_dataframe(pd.read_csv('data/train.csv'), (0.9, 0.01, 0.04, 0.05)))\n",
    "\n",
    "datasets = [ImageDataset(df, transform=transform) for df in df_slices]\n",
    "loaders = [DataLoader(dataset, batch_size=batch_size, shuffle=True) for dataset in datasets]\n",
    "\n",
    "train_dataset, train_threshold_dataset, valid_dataset, test_dataset = datasets\n",
    "train_loader, train_threshold_loader, valid_loader, test_loader = loaders\n",
    "\n",
    "submit_df = pd.read_csv('data/submit.csv')\n",
    "submit_dataset = ImageDataset(submit_df, transform=transform)\n",
    "submit_loader = DataLoader(submit_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/image-comparison/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/image-comparison/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Initializing ContrastiveLoss and Optimizer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218d2a8a18b94dff894c6912e5115b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training model:   0%|          | 0/1864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SiameseNetworkClassifier()\n",
    "train(model, *loaders, epochs=10, max_batches=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dfc8f8d158544b2afb1ab9fda62005f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Next Images', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6e18d276934836b8d2cc60de052a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Check on what's wrong with our model\n",
    "\"\"\"\n",
    "\n",
    "mislabeled(model, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
