{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Imports\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import os\n",
    "from itertools import islice\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchmetrics.classification import BinaryF1Score\n",
    "\n",
    "from torchvision.models import resnet152\n",
    "from torchvision.models.resnet import ResNet152_Weights\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    https://towardsdatascience.com/a-friendly-introduction-to-siamese-networks-85ab17522942\n",
    "\"\"\"\n",
    "\n",
    "class SiameseNetworkClassifier(nn.Module):\n",
    "    def __init__(self, device='mps'):\n",
    "        super(SiameseNetworkClassifier, self).__init__()\n",
    "\n",
    "        # Replace with frozen ResNet152 feature layers\n",
    "        resnet = resnet152(weights=ResNet152_Weights.IMAGENET1K_V1)\n",
    "        # Freeze all layers\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Split the model into frozen and hot layers\n",
    "        self.frozen = nn.Sequential(*list(resnet.children())[:-1]) \n",
    "        self.hot = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(resnet.fc.in_features, 50)\n",
    "        )\n",
    "\n",
    "        self.threshold = torch.tensor(0.)\n",
    "\n",
    "        self.device = torch.device(device)\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, images1, images2):\n",
    "        output1 = self.hot(self.frozen(images1))\n",
    "        output2 = self.hot(self.frozen(images2))\n",
    "        return F.pairwise_distance(output1, output2)\n",
    "        \n",
    "    def update_threshold(self, loader, max_batches=None):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            distances = []\n",
    "            labels = []\n",
    "            for images1, images2, equals in islice(loader, max_batches):\n",
    "                distance = self.forward(images1.to(self.device), images2.to(self.device))\n",
    "                distances.append(distance.cpu())\n",
    "                labels.append(equals)\n",
    "    \n",
    "            distances = torch.cat(distances)\n",
    "            labels = torch.cat(labels)\n",
    "            log_reg = LogisticRegression(penalty=None)\n",
    "            log_reg.fit(distances.reshape((-1, 1)), labels)\n",
    "            self.threshold = (-log_reg.intercept_ / log_reg.coef_).item()\n",
    "\n",
    "    # TODO refactor this method so we don't have to call .to(self.device) ? \n",
    "    def predict(self, images1, images2):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            images1 = images1.to(self.device)\n",
    "            images2 = images2.to(self.device)\n",
    "            distances = self.forward(images1, images2)\n",
    "            return (distances < self.threshold).int().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "max_submit_id = 22661"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.Resize(300),\n",
    "    T.CenterCrop(300),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "df_slices = list(split_dataframe(pd.read_csv('data/train.csv'), (0.9, 0.01, 0.04, 0.05)))\n",
    "datasets = [ImageDataset(df, transform=transform) for df in df_slices]\n",
    "loaders = [DataLoader(dataset, batch_size=batch_size, shuffle=(i == 0)) for i, dataset in enumerate(datasets)]\n",
    "\n",
    "train_data, train_threshold_data, valid_data, test_data = df_slices\n",
    "train_dataset, train_threshold_dataset, valid_dataset, test_dataset = datasets\n",
    "train_loader, train_threshold_loader, valid_loader, test_loader = loaders\n",
    "\n",
    "submit_df = pd.read_csv('data/submit.csv')\n",
    "submit_dataset = ImageDataset(submit_df, transform=transform)\n",
    "submit_loader = DataLoader(submit_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = SiameseNetworkClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61707c540260453b9022e3bab5bd2734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch         : 0\n",
      "Loss          : 0.713796\n",
      "Train fscore  : 1.0000\n",
      "Valid fscore  : 1.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d48a0026d17c452e8664fc2f7d3dd9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch         : 1\n",
      "Loss          : 0.844584\n",
      "Train fscore  : 1.0000\n",
      "Valid fscore  : 1.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf907330e5d94918a56bad26e0b5dcb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch         : 2\n",
      "Loss          : 0.856460\n",
      "Train fscore  : 1.0000\n",
      "Valid fscore  : 1.0000\n",
      "Test fscore   : 1.0000\n"
     ]
    }
   ],
   "source": [
    "train(model, *loaders, epochs=3, max_batches=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6e8c1d7e4c49548dc07f6dffbb86d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Next Images', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7179052e7a3845b99d5375f8b3fa7495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Check on what's wrong with our model\n",
    "\"\"\"\n",
    "\n",
    "mislabeled(model, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Save predictions for the submission\n",
    "\"\"\"\n",
    "\n",
    "max_submit_id = 22661\n",
    "save_submission(model, submit_loader, max_submit_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
