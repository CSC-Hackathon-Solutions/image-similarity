{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Basic imports\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchmetrics.classification import BinaryF1Score\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from DataHandlers import ImageDataset, InMemDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Wrapper class wraps the model and simplifies the testing, training and debugging routine.\n",
    "    The provided model should have following methods in order to work correctly with the Wrapper:\n",
    "        \n",
    "        1. method _train: dict(loader) -> Unit\n",
    "            Method takes only argument `loaders` - dict consisting of train, valid, test, submit loaders\n",
    "            \n",
    "            train, valid, test loaders provide batches of first images from the pair, second images and \n",
    "            labels whether those images are equal\n",
    "            \n",
    "        2. method predict: images1, images2 -> tensor of 0/1\n",
    "        \n",
    "\"\"\"\n",
    "\n",
    "class Wrapper():\n",
    "\n",
    "    \"\"\"\n",
    "        Construct loaders objects, set local variables.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "                self, \n",
    "                model, \n",
    "                paths = {'train': 'data/train.csv', 'submit': 'data/submit.csv', 'small': 'data/small.csv'},\n",
    "                transform = None,\n",
    "                batch_size = 32,\n",
    "            ):\n",
    "        \n",
    "        self.model = model\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        if transform is None:\n",
    "            transform = T.Compose([\n",
    "                T.Resize(200),\n",
    "                T.CenterCrop(200),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])\n",
    "\n",
    "        train = pd.read_csv(paths['train'])  \n",
    "        n = len(train)\n",
    "        \n",
    "        submit = pd.read_csv(paths['submit'])\n",
    "        self.max_submit_id = 22661\n",
    "        \n",
    "        small = pd.read_csv(paths['small'])\n",
    "        \n",
    "        dataset_types = ['train', 'valid', 'test', 'submit', 'small']        \n",
    "        self.datasets = {\n",
    "            'train'  : ImageDataset(train[:int(n * 0.8)], transform=transform),\n",
    "            'valid'  : ImageDataset(train[int(n * 0.8):int(n * 0.9)], transform=transform),\n",
    "            'test'   : ImageDataset(train[int(n * 0.9):], transform=transform),\n",
    "            'small' : ImageDataset(small, transform=transform),\n",
    "            'submit' : ImageDataset(submit, transform=transform)\n",
    "        }\n",
    "        \n",
    "        self.loaders = {\n",
    "            dataset_type: DataLoader(dataset, self.batch_size, shuffle=(dataset_type=='train' or dataset_type=='small'))\n",
    "            for dataset_type, dataset in self.datasets.items()\n",
    "        } \n",
    "\n",
    "    \"\"\"\n",
    "        Wrapper function for model training.\n",
    "    \"\"\"\n",
    "    def train(self):\n",
    "        print('Started training model')\n",
    "        self.model._train(self.loaders)\n",
    "        print('Finished training model\\n')\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "        Calculates f-scores on samples for all the loaders.\n",
    "    \"\"\"\n",
    "    def fscore(self, num_batches=10):\n",
    "        def _count(loader):\n",
    "            preds, truth = [], []\n",
    "            for (images1, images2, equals), _ in zip(loader, range(num_batches)):\n",
    "                preds.append(self.model.predict(images1, images2))\n",
    "                truth.append(equals)\n",
    "\n",
    "            preds = torch.cat(preds)\n",
    "            truth = torch.cat(truth)\n",
    "\n",
    "            preds_bin = (preds > 0.5).int() # todo \n",
    "            f1 = f1_score(truth.numpy(), preds_bin.numpy())\n",
    "            return f1\n",
    "    \n",
    "        print('Started calculating f-score')\n",
    "        print(f'Train       : {_count(self.loaders[\"train\"]): .3f}')\n",
    "        print(f'Small train : {_count(self.loaders[\"small\"]): .3f}')\n",
    "        print(f'Validation  : {_count(self.loaders[\"valid\"]): .3f}') \n",
    "        print(f'Test        : {_count(self.loaders[\"test\"]): .3f}\\n') \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "        Shows example images from each loader available.\n",
    "    \"\"\"\n",
    "    def _test_loaders(self):\n",
    "        print('Examples of images from the supported loaders:')\n",
    "        to_show = {}\n",
    "        for loader_type, loader in self.loaders.items():\n",
    "            image1, image2, _ = next(iter(loader))\n",
    "            image1 = image1[0]\n",
    "            image2 = image2[0]\n",
    "            to_show[loader_type + '-1'] = image1\n",
    "            to_show[loader_type + '-2'] = image2\n",
    "        num_images = len(to_show)\n",
    "        fig, axs = plt.subplots(1, num_images, figsize=(15, 15))\n",
    "\n",
    "        for i, (name, img) in enumerate(to_show.items()):\n",
    "            axs[i].imshow(img.numpy().transpose(1,2,0).clip(0, 254), cmap='gray')\n",
    "            axs[i].set_title(name)\n",
    "            axs[i].axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "        Tries to find and show mislabeled images from the specified loader.\n",
    "    \"\"\"\n",
    "    def mislabeled(self, loader='small'):\n",
    "        loader = self.loaders[loader]\n",
    "\n",
    "        def mislabeled_inner():\n",
    "            for images1, images2, equal in loader:\n",
    "                preds = self.model.predict(images1, images2)\n",
    "                if (preds == equal).all(): \n",
    "                    continue\n",
    "                else:\n",
    "                    for index in (preds != equal).nonzero():\n",
    "                        yield (images1[index], images2[index], preds[index], equal[index])\n",
    "\n",
    "        button = widgets.Button(description=\"Next Images\")\n",
    "        output = widgets.Output()\n",
    "\n",
    "        def on_button_clicked(b):\n",
    "            with output:\n",
    "                clear_output()\n",
    "                image1, image2, pred, truth = next(mislabeled_gen)\n",
    "                def torch2np(x): return x.squeeze().numpy().transpose(1,2,0).clip(0,244)\n",
    "                image1 = torch2np(image1)\n",
    "                image2 = torch2np(image2)\n",
    "                fig, axs = plt.subplots(1, 3, figsize=(14,7))\n",
    "                axs[0].imshow(image1)\n",
    "                axs[1].imshow(image2)\n",
    "                axs[2].imshow(np.abs(image1 - image2))\n",
    "                suptitle = f'Predicted: {pred.item()}\\nTruth: {truth.item()}'\n",
    "                try:\n",
    "                    suptitle += f'\\nmodel.forward(): {self.model.forward(image1, image2)}'\n",
    "                except:\n",
    "                    pass\n",
    "                fig.suptitle(suptitle)\n",
    "                plt.show()\n",
    "\n",
    "        button.on_click(on_button_clicked)\n",
    "        display(button, output)\n",
    "        mislabeled_gen = mislabeled_inner()\n",
    "        on_button_clicked(None)  # show the first images\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "        Saves predictions that should be submitted to kaggle.\n",
    "    \"\"\"\n",
    "    def save_test_preds(self, path='res.csv'):\n",
    "        print(f'Started saving test predictions to {path}')\n",
    "        ids = []\n",
    "        preds = []\n",
    "            \n",
    "        for images1, images2, id_ in tqdm(self.loaders['submit']):\n",
    "            preds.extend(self.model.predict(images1, images2))\n",
    "            ids.extend(id_)\n",
    "            \n",
    "        all_ids = pd.DataFrame({\n",
    "            'ID': range(2, self.max_submit_id + 1),\n",
    "        })\n",
    "        res = pd.DataFrame({\n",
    "            'ID': [obj.item() for obj in ids],\n",
    "            'is_same': [obj.item() for obj in preds]\n",
    "        }).drop_duplicates()\n",
    "\n",
    "        res = all_ids.merge(res, on='ID', how='left').fillna(0)\n",
    "        res.to_csv(path, index=False)\n",
    "        print(f'Saved test predictions to {path}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, distance, label):\n",
    "        loss_contrastive = torch.mean(label * torch.pow(distance, 2) +\n",
    "                                      (1 - label) * torch.pow(torch.clamp(self.margin - distance, min=0), 2))\n",
    "\n",
    "        return loss_contrastive\n",
    "\n",
    "class SiameseNetworkClassifier(nn.Module):\n",
    "    def __init__(self, device='mps'):\n",
    "        super(SiameseNetworkClassifier, self).__init__()\n",
    "\n",
    "        # Replace with frozen ResNet50 feature layers\n",
    "        resnet50 = models.resnet50(pretrained=True)\n",
    "        # Freeze all layers\n",
    "        for param in resnet50.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Split the model into frozen and hot layers\n",
    "        self.frozen_layers = nn.Sequential(*list(resnet50.children())[:-1]) \n",
    "        self.hot_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(resnet50.fc.in_features, 50)\n",
    "        )\n",
    "\n",
    "        self.threshold = torch.tensor(0.)\n",
    "\n",
    "        self.device = torch.device(device)\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, images1, images2):\n",
    "        output1 = self.hot_layers(self.frozen_layers(images1))\n",
    "        output2 = self.hot_layers(self.frozen_layers(images2))\n",
    "        return F.pairwise_distance(output1, output2)\n",
    "\n",
    "    # TODO refactor this method so we don't have to call .to(self.device) ? \n",
    "    def predict(self, images1, images2):\n",
    "        images1 = images1.to(self.device)\n",
    "        images2 = images2.to(self.device)\n",
    "        distances = self.forward(images1, images2)\n",
    "        return (distances < self.threshold).int().cpu()\n",
    "        \n",
    "    def _update_threshold(self, loader, max_batches=50):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            distances = []\n",
    "            labels = []\n",
    "            for (images1, images2, equals), _ in zip(loader, range(max_batches)):\n",
    "                distance = self.forward(images1.to(self.device), images2.to(self.device))\n",
    "                distances.append(distance.cpu())\n",
    "                labels.append(equals)\n",
    "    \n",
    "            distances = torch.cat(distances)\n",
    "            labels = torch.cat(labels)\n",
    "            log_reg = LogisticRegression(penalty=None)\n",
    "            log_reg.fit(distances.reshape((-1, 1)), labels)\n",
    "            self.threshold = (-log_reg.intercept_ / log_reg.coef_).item()\n",
    "\n",
    "    def _evaluate(self, loader, max_batches = 50):\n",
    "        super().eval()\n",
    "        with torch.no_grad():\n",
    "            pos_f1 = BinaryF1Score()\n",
    "            neg_f1 = BinaryF1Score()\n",
    "            for (images1, images2, label), _ in zip(loader, range(max_batches)):\n",
    "                distance = self.forward(images1.to(self.device), images2.to(self.device)).cpu()\n",
    "                pos_f1.update(distance < self.threshold, label)\n",
    "                neg_f1.update(distance > self.threshold, 1 - label)\n",
    "        return (pos_f1.compute() + neg_f1.compute()) / 2\n",
    "\n",
    "\n",
    "    def _train(self, loaders, lr=1e-4, batch_size=32):\n",
    "        criterion = ContrastiveLoss().to(self.device)\n",
    "        # Only parameters of hot layers are optimized\n",
    "        optimizer = torch.optim.Adam(self.hot_layers.parameters(), lr=lr)\n",
    "\n",
    "        for epoch in range(10):\n",
    "            super().train()\n",
    "            for images1, images2, label in tqdm(loaders['small']):\n",
    "                images1 = images1.to(self.device)\n",
    "                images2 = images2.to(self.device)\n",
    "                label = label.to(self.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.forward(images1, images2)\n",
    "                loss = criterion(outputs, label)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            self._update_threshold(loaders['small'], batch_size)\n",
    "\n",
    "            print(f'Epoch {epoch} | Loss:{loss.item()}')\n",
    "            print(f'Train accuracy: {self._evaluate(loaders[\"train\"], batch_size)}')\n",
    "            print(f'Small train dataset accuracy: {self._evaluate(loaders[\"small\"], batch_size)}')\n",
    "            print(f'Valid accuracy: {self._evaluate(loaders[\"valid\"], batch_size)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Create the model and wrapper instances\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# TODO refactor code so that `pretrained is deprecated` warning does not appear\n",
    "model = SiameseNetworkClassifier()\n",
    "wrapper = Wrapper(model, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Train the model.\n",
    "    TODO specify loaders for the train method ?\n",
    "\"\"\"\n",
    "\n",
    "wrapper.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Check on what's wrong with our model\n",
    "\"\"\"\n",
    "\n",
    "wrapper.mislabeled(loader='small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Calculate final f-score.\n",
    "\"\"\"\n",
    "\n",
    "wrapper.fscore(num_batches=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
